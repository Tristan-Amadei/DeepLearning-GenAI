{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYXhEqG-uC3z"
   },
   "source": [
    "# TP Coding a GAN in Pytorch\n",
    "\n",
    "Author : Alasdair Newson\n",
    "\n",
    "alasdair.newson@telecom-paris.fr\n",
    "\n",
    "## Objective:\n",
    "\n",
    "The goal of this TP is to explore GANs applied to the mnist (and possibly cifar10) datasets.\n",
    "\n",
    "We will start with the mnist dataset.\n",
    "\n",
    "### Your task:\n",
    "You need to add the missing parts in the code (parts between # --- START CODE HERE and # --- END CODE HERE or # FILL IN CODE)\n",
    "\n",
    "First of all, let's load some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "meKYIDlUysj6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def pytorch_to_numpy(x):\n",
    "  return x.detach().numpy()\n",
    "\n",
    "\n",
    "# Decide which device we want to run on\n",
    "if (torch.cuda.is_available()):\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgTDA2KIG4Vm"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "We define a function to load the mnist or cifar10 datasets. Note, we normalise the data between -1 and 1 here (this is often the case for GANs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kq9DHNlPiI3o"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)),\n",
    "])\n",
    "\n",
    "# MNIST Dataset\n",
    "mnist_trainset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "mnist_testset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
    "\n",
    "#create data loader with smaller dataset size\n",
    "max_mnist_size = 60000\n",
    "mnist_trainset_reduced = torch.utils.data.random_split(mnist_trainset, [max_mnist_size, len(mnist_trainset)-max_mnist_size])[0] \n",
    "mnist_train_loader = torch.utils.data.DataLoader(mnist_trainset_reduced, batch_size=64, shuffle=True)\n",
    "\n",
    "# download test dataset\n",
    "max_mnist_size = 512\n",
    "mnist_testset_reduced = torch.utils.data.random_split(mnist_testset, [max_mnist_size, len(mnist_testset)-max_mnist_size])[0] \n",
    "mnist_test_loader = torch.utils.data.DataLoader(mnist_testset_reduced, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kpniDL3gekkE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = mnist_trainset_reduced.dataset.train_data.shape[1]\n",
    "n_cols = mnist_trainset_reduced.dataset.train_data.shape[2]\n",
    "n_channels = 1\n",
    "n_pixels = n_rows*n_cols\n",
    "\n",
    "img_shape = (n_rows, n_cols, n_channels)\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h25SHO2dT_Uz"
   },
   "source": [
    "## GAN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3l7szkgMT_3C"
   },
   "outputs": [],
   "source": [
    "## GAN parameters\n",
    "z_dim = 10\n",
    "batch_size = 128\n",
    "## parameters for training\n",
    "n_epochs = 400\n",
    "n_iters_inner=1\t#number of internal loops\n",
    "sample_interval=100\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "\n",
    "# hidden dimensions : careful, the order here is with respect to the generator, and the discriminator is in the opposite order\n",
    "h_dim_1 = 256\n",
    "h_dim_2 = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi7BsXCsytEd"
   },
   "source": [
    "## Model architecture\n",
    "\n",
    "Now, we define the model architecture.\n",
    "\n",
    "For the first dataset, mnist, we are going to use fully connected layers. Implement the following architecture, for the generator and the discriminator :\n",
    "\n",
    "Generator :\n",
    "- Dense layer, to size 256\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, to size 512\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, output size 784\n",
    "- Tanh activation\n",
    "- Reshape to size $28 \\times 28 \\times 1$\n",
    "\n",
    "Discriminator :\n",
    "- Flatten\n",
    "- Dense layer, to size 512\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, output size 256\n",
    "- Leaky ReLU ($\\alpha=0.2$)\n",
    "- Dense layer, output size 1\n",
    "- Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "in24TH-RESPO"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, z_dim, h_dim_1, h_dim_2, n_rows, n_cols, n_channels):\n",
    "      super(Generator, self).__init__()\n",
    "      self.n_rows = n_rows\n",
    "      self.n_cols = n_cols\n",
    "      self.n_channels = n_channels\n",
    "      self.n_pixels = (self.n_rows) * (self.n_cols)\n",
    "      self.h_dim_1 = h_dim_1\n",
    "      self.h_dim_2 = h_dim_2\n",
    "      self.z_dim = z_dim\n",
    "\n",
    "      self.fc1 = nn.Linear(z_dim, h_dim_1)\n",
    "      self.fc2 = nn.Linear(h_dim_1, h_dim_2)\n",
    "      self.fc3 = nn.Linear(h_dim_2, self.n_pixels)\n",
    "\n",
    "  def forward(self, z):\n",
    "      y = F.leaky_relu(self.fc1(z), negative_slope=0.2)\n",
    "      y = F.leaky_relu(self.fc2(y), negative_slope=0.2)\n",
    "      y = torch.tanh(self.fc3(y))\n",
    "      y = y.view(y.size(0), self.n_channels, self.n_rows, self.n_cols)\n",
    "      return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wuXe9NVXOSnD"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, h_dim_2, h_dim_1, z_dim, n_rows, n_cols, n_channels):\n",
    "      super(Discriminator, self).__init__()\n",
    "\n",
    "      self.n_rows = n_rows\n",
    "      self.n_cols = n_cols\n",
    "      self.n_channels = n_channels\n",
    "      self.n_pixels = (self.n_rows) * (self.n_cols)\n",
    "      self.h_dim_1 = h_dim_1\n",
    "      self.h_dim_2 = h_dim_2\n",
    "      self.z_dim = z_dim\n",
    "\n",
    "      self.fc1 = nn.Linear(self.n_pixels, h_dim_2)\n",
    "      self.fc2 = nn.Linear(h_dim_2, h_dim_1)\n",
    "      self.fc3 = nn.Linear(h_dim_1, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = x.view(x.size(0), -1)\n",
    "      y = F.leaky_relu(self.fc1(x), negative_slope=0.2)\n",
    "      y = F.leaky_relu(self.fc2(y), negative_slope=0.2)\n",
    "      y = torch.sigmoid(self.fc3(y))\n",
    "      return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq00Ve8OdOXi"
   },
   "source": [
    "Create generator and discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FP5lYLacdNyK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=784, bias=True)\n",
      ")\n",
      "Discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define generator and discriminator models\n",
    "gen_model = Generator(z_dim, h_dim_1, h_dim_2, n_rows, n_cols, n_channels).to(device)\n",
    "disc_model = Discriminator(h_dim_2, h_dim_1, z_dim, n_rows, n_cols, n_channels).to(device)\n",
    "\n",
    "# Print the models\n",
    "print(gen_model)\n",
    "print(disc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdznIctaESt-"
   },
   "source": [
    "## Loss function\n",
    "\n",
    "\n",
    "The GAN loss function is the following :\n",
    "\\begin{equation}\n",
    "\t\\min_{G} \\max_{D} \\mathbb{E}_{x \\in p_{data}} \\left[ \\log D(x)\\right] +\n",
    "\t\\mathbb{E}_{z \\in p_{z}}\\left[ \\log \\left( 1 - D(G(z)) \\right)\\right],\n",
    "\\end{equation}\n",
    "where $G$ is the generator, $D$ is the discriminator, $z$ is the latent code, which follows a normal distribution.\n",
    "\n",
    "You should notice that this is extremely similar to the binary cross-entropy function. Therefore, there is an intelligent way to train the discriminator : we give it first a batch of real images, and label them as real, and secondly we give a batch of fake images and label them as fake. Therefore, the discriminator training itself is done in two sequential steps (first true, then fake). If the labels are correctly chosen (further on, during training), you can (and __should__) use the binary cross-entropy function.\n",
    "\n",
    "The generator loss, however, must be specified as :\n",
    "- $mean(\\log(1-D(G(z))))$\n",
    "\n",
    "You can use the ```torch.mean``` function for this purpose.\n",
    "\n",
    "\n",
    "The training is carried out sequentially : first we execute a few training steps on the discriminator, and then one on the generator. Therefore, we use two loops : one to train the discriminator (the internal loop) and one to train the generator (external loop, ie. the number of epochs). The GAN training algorithm is as follows :\n",
    "\n",
    "- For $i=0$ to $n-1$\n",
    "  - For $j=0$ to $m-1$\n",
    "    - $x \\leftarrow$ random batch of data\n",
    "    - $z \\leftarrow$ random batch of latent codes\n",
    "    - Train discriminator on real images $x$\n",
    "    - Train discriminator on fake images $G(z)$\n",
    "  - $z \\leftarrow$ random batch of latent codes\n",
    "  - Train discriminator on fake images $G(z)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SbnxHkOsuDOh"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizer_disc = optim.Adam(disc_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
    "optimizer_gen = optim.Adam(gen_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
    "\n",
    "# criterion used for the discriminator loss\n",
    "bce_criterion = nn.BCELoss()  # FILL IN CODE\n",
    "\n",
    "# criterion used for the generator loss\n",
    "def loss_fn_gen(d_gen_data):\n",
    "  loss_gen = torch.mean(torch.log(1 - d_gen_data))  # FILL IN CODE\n",
    "  return loss_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z0IzHPlLLtb"
   },
   "source": [
    "### Sampling function\n",
    "\n",
    "We now create a function to sample several images during training (to follow the convergence of the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6oaCO17ZGzWN"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_images(generator,z_dim, rand_seed=30):\n",
    "  #np.random.seed(rand_seed)\n",
    "  r, c = 5, 5\n",
    "  z_random = torch.randn(r * c, 1, z_dim, dtype=torch.float, device=device) #np.random.normal(0, 1, (r * c, z_dim))\n",
    "  \n",
    "  gen_imgs = np.transpose( generator(z_random).cpu().detach().numpy() , (0,2,3,1))\n",
    "\n",
    "  # Rescale images 0 - 1\n",
    "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "  fig, axs = plt.subplots(r, c)\n",
    "  cnt = 0\n",
    "  for i in range(r):\n",
    "    for j in range(c):\n",
    "      #black and white images\n",
    "      if(gen_imgs.shape[3] == 1):\n",
    "        axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "      elif(gen_imgs.shape[3] == 3):   #colour images\n",
    "        gen_imgs_temp = gen_imgs.copy()\n",
    "        gen_imgs_temp = 255.*np.clip(gen_imgs_temp,0.0,1.0) \n",
    "        axs[i,j].imshow(gen_imgs_temp[cnt, :,:,:].astype(np.uint8))\n",
    "      else:\n",
    "        print('Error, unsupported channel size. Dude, I don''t know what you want me to do.\\\n",
    "            I can''t handle this data. You''ve made me very sad ...')\n",
    "      axs[i,j].axis('off')\n",
    "      cnt += 1\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfcwQGo7G0zA"
   },
   "source": [
    "## Training\n",
    "\n",
    "We are now ready to train the network. Here is the training algorithm again :\n",
    "\n",
    "- For $i=0$ to $n_{epochs}-1$\n",
    "  - For $j=0$ to $n_{iters\\_inner}-1$\n",
    "    - $x \\leftarrow$ random batch of data\n",
    "    - $z \\leftarrow$ random batch of latent codes\n",
    "    - Train discriminator on real images $x$\n",
    "    - Train discriminator on fake images $G(z)$\n",
    "  - $z \\leftarrow$ random batch of latent codes\n",
    "  - Train discriminator on fake images $G(z)$\n",
    "\n",
    "You can use ```torch.randn``` to create a batch of random Gaussian latent codes:\n",
    "- ```torch.randn(dim_1, dim_2, dim_3, device=device)```\n",
    "where ```dim_1, dim_2, dim_3``` are the dimensions of the Tensor.\n",
    "\n",
    "To create a batch of labels equal to 1, use the following function:\n",
    "- ```torch.ones(my_shape, dtype=torch.float, device=device)```\n",
    "where ```my_shape``` is the shape of the tensor of ones that you wish. \n",
    "\n",
    "Similarly, to create a batch of zeros, use:\n",
    "- ```torch.zeros(my_shape, dtype=torch.float, device=device)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TIZVW79aU0CZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLk9cmsQLL--"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "sample_interval=1\n",
    "\n",
    "print(\"Starting Training\")\n",
    "# For each epoch\n",
    "for epoch in range(50):\n",
    "  # For each batch in the dataloader\n",
    "  for i, data in enumerate(mnist_train_loader, 0):\n",
    "    for iter_inner in range(0,n_iters_inner):\n",
    "        \n",
    "      ############################\n",
    "      ### Train discriminator\n",
    "      ############################\n",
    "      ## Train with true data batch\n",
    "      disc_model.zero_grad()\n",
    "      # create true data and labels \n",
    "      true_imgs = data[0].to(device)\n",
    "      true_labels = torch.ones(true_imgs.size(0), dtype=torch.float, device=device) # FILL IN HERE. CAREFUL, WE WANT A 1-DIMENSIONAL TENSOR OF LABELS (DUE TO THE \"VIEW\" IN NEXT LINE)\n",
    "      # put true data through discriminator\n",
    "      d_output_true = disc_model(true_imgs).view(-1) # FILL IN HERE\n",
    "      # bce loss on true data\n",
    "      d_loss_true = bce_criterion(d_output_true, true_labels) # FILL IN HERE\n",
    "      # backpropagation for discriminator, true loss\n",
    "      d_loss_true.backward()\n",
    "      disc_true_value = d_output_true.mean().item()\n",
    "\n",
    "      ## Train with fake data batch\n",
    "      # create fake data and labels\n",
    "      # generate batch of random latent vectors\n",
    "      z_latent_noise = torch.randn(true_imgs.size(0), 1, z_dim, device=device) # FILL IN HERE\n",
    "      # Generate batch of fake images\n",
    "      fake_imgs = gen_model(z_latent_noise)  # FILL IN HERE\n",
    "      fake_labels = torch.zeros(fake_imgs.size(0), dtype=torch.float, device=device) # FILL IN HERE\n",
    "      # put fake data through discriminator\n",
    "      disc_output_fake = disc_model(fake_imgs.detach()).view(-1)\n",
    "      # bce loss on fake data\n",
    "      disc_loss_fake = bce_criterion(disc_output_fake, fake_labels)  # FILL IN HERE\n",
    "      # backpropagation for discriminator, fake loss\n",
    "      disc_loss_fake.backward()\n",
    "      disc_fake_value = disc_output_fake.mean().item()\n",
    "      # Update discriminator\n",
    "      optimizer_disc.step()\n",
    "\n",
    "      d_loss_total = d_loss_true+disc_loss_fake\n",
    "\n",
    "    ############################\n",
    "    ### Train generator\n",
    "    ############################\n",
    "    gen_model.zero_grad()\n",
    "    # We have updated the discriminator, so we need to update the output of the discriminator\n",
    "    disc_gen_output_fake = disc_model(fake_imgs).view(-1) # FILL IN HERE\n",
    "    # Generator loss, using the custom loss\n",
    "    g_loss = loss_fn_gen(disc_gen_output_fake) # FILL IN HERE\n",
    "    # backpropagation for generator\n",
    "    g_loss.backward()\n",
    "    #D_G_z2 = output.mean().item()\n",
    "    # Update generator\n",
    "    optimizer_gen.step()\n",
    "\n",
    "    # Output training stats\n",
    "    if i % 200 == 0:\n",
    "      print('[%d/%d][%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
    "      % (epoch, n_epochs, i, len(mnist_train_loader),d_loss_total.item(), g_loss.item(), disc_true_value, disc_fake_value ))\n",
    "\n",
    "    # Save Losses for plotting later\n",
    "    G_losses.append(g_loss.item())\n",
    "    D_losses.append(d_loss_total.item())\n",
    "\n",
    "\n",
    "  if(epoch % sample_interval == 0):\n",
    "    sample_images(gen_model,z_dim, rand_seed=30)\n",
    "\n",
    "# end samples\n",
    "sample_images(gen_model,z_dim, rand_seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "sample_interval=1\n",
    "\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(50):\n",
    "  for i, data in enumerate(mnist_train_loader, 0):\n",
    "    for iter_inner in range(0,n_iters_inner):\n",
    "        \n",
    "      ############################\n",
    "      ### Train discriminator\n",
    "      ############################\n",
    "\n",
    "      ## Train with true data batch\n",
    "      disc_model.zero_grad()\n",
    "      true_imgs = data[0].to(device)\n",
    "      true_labels = torch.ones(true_imgs.size(0), dtype=torch.float, device=device)\n",
    "      d_output_true = disc_model(true_imgs).view(-1) \n",
    "      d_loss_true = bce_criterion(d_output_true, true_labels)\n",
    "      d_loss_true.backward()\n",
    "      disc_true_value = d_output_true.mean().item()\n",
    "\n",
    "      ## Train with fake data batch\n",
    "      z_latent_noise = torch.randn(true_imgs.size(0), 1, z_dim, device=device) \n",
    "      fake_imgs = gen_model(z_latent_noise) \n",
    "      fake_labels = torch.zeros(fake_imgs.size(0), dtype=torch.float, device=device)\n",
    "      disc_output_fake = disc_model(fake_imgs.detach()).view(-1)\n",
    "      disc_loss_fake = bce_criterion(disc_output_fake, fake_labels)\n",
    "      disc_loss_fake.backward()\n",
    "      disc_fake_value = disc_output_fake.mean().item()\n",
    "      optimizer_disc.step()\n",
    "\n",
    "      d_loss_total = d_loss_true+disc_loss_fake\n",
    "\n",
    "    ############################\n",
    "    ### Train generator\n",
    "    ############################\n",
    "    gen_model.zero_grad()\n",
    "    disc_gen_output_fake = disc_model(fake_imgs).view(-1)\n",
    "    g_loss = loss_fn_gen(disc_gen_output_fake) \n",
    "    g_loss.backward()\n",
    "    optimizer_gen.step()\n",
    "\n",
    "    # Output training stats\n",
    "    if i % 200 == 0:\n",
    "      print('[%d/%d][%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
    "      % (epoch, n_epochs, i, len(mnist_train_loader),d_loss_total.item(), g_loss.item(), disc_true_value, disc_fake_value ))\n",
    "\n",
    "    # Save Losses for plotting later\n",
    "    G_losses.append(g_loss.item())\n",
    "    D_losses.append(d_loss_total.item())\n",
    "\n",
    "\n",
    "  if(epoch % sample_interval == 0):\n",
    "    sample_images(gen_model,z_dim, rand_seed=30)\n",
    "\n",
    "# end samples\n",
    "sample_images(gen_model,z_dim, rand_seed=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAxaGxO6w8op"
   },
   "source": [
    "Hopefully, you have managed to get the GAN working. Yoohoo !! You should notice that the results are much less smooth than those of the variational autoencoder. This is normal, in general a GAN produces sharper results, but is quite difficult to get working well. You can try and modify the latent space to see whether this improves the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating in the latent space\n",
    "\n",
    "One of the main interests in the latent space is to be able to __navigate__ in it. For instance, one operation which is very common is to take two points $z_0$ and $z_1$ and to interpolate between the two. The images resulting from the generation of the interpolated points should ideally be a mix between the two initial points. \n",
    "\n",
    "The simplest method of interpolation is simply linear interpolation along the line connecting the two points. Obviously, this supposes that the latent space is linear in some sense, which may not be true, but we are going to take this approach here. \n",
    "\n",
    "First, find two inital points $z_0$ and $z_1$ which you feel represent two different digits well, and display their resulting generated images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first image\n",
    "random_seed = 110 # change this seed to find the best image\n",
    "torch.manual_seed(random_seed)\n",
    "z_0 = ... # FILL IN HERE\n",
    "x_0 = ... # FILL IN HERE\n",
    "\n",
    "random_seed = 64 # change this seed to find the best image\n",
    "torch.manual_seed(random_seed)\n",
    "z_1 = ... # FILL IN HERE\n",
    "x_1 = ... # FILL IN HERE\n",
    "\n",
    "# display images\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, carry out the interpolation between these two points. You should __include__ the starting and ending codes $z_0$ and $z_1$. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interpolation = 20\n",
    "\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "\n",
    "fig, axs = plt.subplots(1, n_interpolation,figsize=(20,20))\n",
    "for i in range(n_interpolation):\n",
    "  #black and white images\n",
    "  axs[i].imshow( ... , cmap='gray')  # FILL IN HERE\n",
    "  axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the quality of the output images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Now, we are going to evaluate this navigation. We will investigate the following property:\n",
    "\n",
    "- We are going to see whether by navigating between two points, the model produces images which are categorised in either of the classes (beginning class or end class), or if it traverses a region which is categorised in another class;\n",
    "\n",
    "For this, we will first need a classification network. Use the following architecture :\n",
    "\n",
    "- conv2d, filter size  3×3 , 32 filters, stride=(2,2), padding=\"SAME\"\n",
    "- ReLU\n",
    "- conv2d, filter size  3×3 , 32 filters, stride=(2,2), padding=\"SAME\"\n",
    "- ReLU\n",
    "- MaxPool2D, stride=(2,2)\n",
    "- Flatten\n",
    "- Dense layer\n",
    "\n",
    "We also define a function ```get_accuracy``` to calculate the accuracy of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mnist classifier model, loss function, optimiser and the function 'get_accuracy' (already done)\n",
    "\n",
    "# BEGIN FILL IN HERE\n",
    "\n",
    "# END FILL IN HERE\n",
    "\n",
    "def get_accuracy(x_pred,x_label):\n",
    "  acc = torch.sum(x_pred == x_label)/(x_pred.shape[0])\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "\n",
    "# FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, create a function which returns the classification returned by this network on mnist images. Remember, here we want the argmax, rather than the maximum probability. __Note__: the torch.max function returns a tuple: (max_values, max_indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mnist_class(imgs_in,classification_model):\n",
    "  output_classes = ... # FILL IN HERE\n",
    "  return(output_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out and print the classification of your interpolated latent space images. What are your remarks ? Does the latent space navigation traverse regions with classes other than those of $z_0$ and $z_1$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_classes = ... # FILL IN HERE\n",
    "print(z_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKRGvUZaVWK3"
   },
   "source": [
    "# Training on CIFAR (optional)\n",
    "\n",
    "If you want to try another, more challenging database, use the above code and modify it to carry out the GAN training on the CIFAR10 database. Note, it can take a long time to get good results\n",
    "\n",
    "First, we download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97W-qqT0GtaE"
   },
   "outputs": [],
   "source": [
    "# convert input to Pytorch tensors\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)),\n",
    "])\n",
    "\n",
    "# extract mnist data\n",
    "cifar_trainset = datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "print(cifar_trainset)\n",
    "\n",
    "#create data loader with smaller dataset size\n",
    "max_cifar_size = 2000\n",
    "cifar_trainset_reduced = torch.utils.data.random_split(cifar_trainset, [max_cifar_size, len(cifar_trainset)-max_cifar_size])[0] \n",
    "cifar_train_loader = torch.utils.data.DataLoader(cifar_trainset_reduced, batch_size=64, shuffle=True)\n",
    "\n",
    "# download test dataset\n",
    "cifar_testset = datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "cifar_test_loader = torch.utils.data.DataLoader(cifar_testset, batch_size=64, shuffle=True)\n",
    "\n",
    "n_rows = 32\n",
    "n_cols = 32\n",
    "n_channels = 3\n",
    "n_pixels = n_rows*n_cols\n",
    "\n",
    "img_shape = (n_rows, n_cols, n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxhv31g6NYMS"
   },
   "source": [
    "Now, we can redefine the hyper-parameters of the model (change if you wish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vqp1dLHWNcY2"
   },
   "outputs": [],
   "source": [
    "## GAN parameters\n",
    "z_dim = 10\n",
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "## parameters for training\n",
    "n_iters_inner=1\t#number of internal loops\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwUdFDCXNevC"
   },
   "source": [
    "For this case of CIFAR, implement the following architecture :\n",
    "\n",
    "- Generator :\n",
    "  - Dense layer to size 1024\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Reshape, to size $4 \\times 4 \\times64$\n",
    "  - % size = $4\\times4\\times64$\n",
    "  - Conv2d, n_channels=16,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
    "  - Upsample(scale_factor=(2,2))\n",
    "  - %size = $8\\times 8\\times 16$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2d, n_channels=16,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
    "  - Upsample(scale_factor=(2,2))\n",
    "  - %size=$16 \\times 16 \\times 16$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2d, n_channels=3,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
    "  - Upsample(scale_factor=(2,2))\n",
    "  - %size = $32 \\times 32 \\times 3$\n",
    "  - Tanh activation ( you can use ```Activation('tanh')```)\n",
    "\n",
    "- Discriminator :\n",
    "  - % input size : $32 \\times 32 \\times 3$\n",
    "  - Conv2D, 32 filters, kernel size = (3,3), strides = (1,1),padding = same\n",
    "  - % size $32 \\times 32 \\times 32$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
    "  - %size : $16 \\times 16 \\times 32$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2D, 64 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
    "  - % size : $8 \\times 8 \\times 64$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
    "  - % size : $4 \\times 4 \\times 32$\n",
    "  - Leaky ReLU ($\\alpha=0.2$)\n",
    "  - Flatten\n",
    "  - Dense layer to size 1\n",
    "  - Sigmoid activation\n",
    "\n",
    "  Implement this architecture below, and train the GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5m3--yiNhb2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGz2YT0KR2tX"
   },
   "source": [
    "Now, carry out the training (use code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQcGMK7YR3JY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
