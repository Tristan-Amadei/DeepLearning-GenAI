{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dnn import DNN\n",
    "from dbn import DBN\n",
    "from load_data import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_alpha = lire_alpha_digits(['A', 'E', 'X', '4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "patience = 10\n",
    "\n",
    "nb_layers = 3\n",
    "neurons = [512, 256, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn_alpha = DBN(X=binary_alpha, L=nb_layers, qs=neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdbn_alpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_DBN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\trist\\OneDrive\\Bureau\\Cours\\ENSAE\\M2DS\\DL II\\src\\notebooks\\..\\dbn.py:30\u001b[0m, in \u001b[0;36mDBN.train_DBN\u001b[1;34m(self, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rbm \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbms):\n\u001b[0;32m     29\u001b[0m     rbm\u001b[38;5;241m.\u001b[39mupdate_X(h)\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_RBM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_error_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     h, _ \u001b[38;5;241m=\u001b[39m rbm\u001b[38;5;241m.\u001b[39mentree_sortie_RBM(h)\n",
      "File \u001b[1;32mc:\\Users\\trist\\OneDrive\\Bureau\\Cours\\ENSAE\\M2DS\\DL II\\src\\notebooks\\..\\rbm.py:61\u001b[0m, in \u001b[0;36mRBM.train_RBM\u001b[1;34m(self, epochs, learning_rate, batch_size, print_error_every, plot_errors)\u001b[0m\n\u001b[0;32m     58\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_shuffled[i: i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Gibbs sampling\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m probabilities_h_given_v0, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentree_sortie_RBM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m _, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msortie_entree_RBM(h)\n\u001b[0;32m     63\u001b[0m probabilities_h_given_v1, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentree_sortie_RBM(v)\n",
      "File \u001b[1;32mc:\\Users\\trist\\OneDrive\\Bureau\\Cours\\ENSAE\\M2DS\\DL II\\src\\notebooks\\..\\rbm.py:36\u001b[0m, in \u001b[0;36mRBM.entree_sortie_RBM\u001b[1;34m(self, v)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentree_sortie_RBM\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[0;32m     35\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m+\u001b[39m v \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW)\n\u001b[1;32m---> 36\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m probabilities)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m probabilities, values\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dbn_alpha.train_DBN(epochs=epochs, learning_rate=learning_rate, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1200 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_gen = dbn_alpha.generer_image_DBN(num_samples=30, gibbs_steps=500, image_size=(20, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dnn(pretrain, nb_layers, neurons, suptitle, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \n",
    "            epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=True):\n",
    "    dnn = DNN(X_train, y_train, num_classes=10, num_hidden_layers=nb_layers, neurons=neurons,\n",
    "                X_val=X_test, y_val=y_test)\n",
    "    if pretrain:\n",
    "        dnn.pretrain_DNN(epochs=epochs, learning_rate=learning_rate, batch_size=batch_size)\n",
    "    losses, accuracies, val_losses, val_accuracies = dnn.retropropagation(\n",
    "    epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=plot_, patience=patience, \n",
    "    suptitle=suptitle)\n",
    "    return dnn, losses, accuracies, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(l, path):\n",
    "    with open(path, \"wb\") as fp: \n",
    "        pickle.dump(l, fp)\n",
    "        \n",
    "def open_list(path):\n",
    "    with open(path, \"rb\") as fp:   \n",
    "        l = pickle.load(fp)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs(digit_figure):\n",
    "    if not os.path.exists(f'figure{digit_figure}'):\n",
    "        os.mkdir(f'figure{digit_figure}')\n",
    "    if not os.path.exists(f'figure{digit_figure}/dnns'):\n",
    "        os.mkdir(f'figure{digit_figure}/dnns')\n",
    "    if not os.path.exists(f'.figure{digit_figure}/losses'):\n",
    "        os.mkdir(f'figure{digit_figure}/loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(i, losses_nb_layers, accuracies_nb_layers, val_losses_nb_layers, val_accuracies_nb_layers, ax, xlabel):\n",
    "    ax[0].plot(losses_nb_layers[i][0], label='Train set- random init')\n",
    "    ax[0].plot(losses_nb_layers[i][1], '--', label='Train set - pretrain')\n",
    "    ax[0].plot(val_losses_nb_layers[i][0], label='Valid set- random init')\n",
    "    ax[0].plot(val_losses_nb_layers[i][1], '--', label='Valid set - pretrain')\n",
    "    ax[0].set_xlabel(xlabel)\n",
    "    ax[0].grid('on')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].plot(accuracies_nb_layers[i][0], label='Train set- random init')\n",
    "    ax[1].plot(accuracies_nb_layers[i][1], '--', label='Train set - pretrain')\n",
    "    ax[1].plot(val_accuracies_nb_layers[i][0], label='Valid set- random init')\n",
    "    ax[1].plot(val_accuracies_nb_layers[i][1], '--', label='Valid set - pretrain')\n",
    "    ax[1].grid('on')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    if i == 0:\n",
    "        ax[0].set_title('Loss')\n",
    "        ax[1].set_title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_save(digit_figure, name, nb_layers, neurons, suptitle,\n",
    "                 X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=True):\n",
    "    if not os.path.exists(f'figure{digit_figure}/dnns/dnn_{name}.pkl'):\n",
    "        dnn, losses, accuracies, val_losses, val_accuracies = run_dnn(False, nb_layers, neurons, suptitle=suptitle + ' - random init', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \n",
    "                epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=plot_)\n",
    "        clear_output(wait=True)\n",
    "        dnn.save_weights(f'figure{digit_figure}/dnns/dnn_{name}.pkl')\n",
    "        save_list(losses, f'figure{digit_figure}/losses/losses_{name}.pkl')\n",
    "        save_list(accuracies, f'figure{digit_figure}/losses/accuracies_{name}.pkl')\n",
    "        save_list(val_losses, f'figure{digit_figure}/losses/val_losses_{name}.pkl')\n",
    "        save_list(val_accuracies, f'figure{digit_figure}/losses/val_accuracies_{name}.pkl')\n",
    "\n",
    "    print('pretrain')\n",
    "    if not os.path.exists(f'figure{digit_figure}/dnns/pretrain_dnn_{name}.pkl'):\n",
    "        dnn, losses_pretrain, accuracies_pretrain, val_losses_pretrain, val_accuracies_pretrain = run_dnn(True, nb_layers, neurons, suptitle=suptitle + '- pretrain', X_train=X_train, y_train=y_train, \n",
    "                    X_test=X_test, y_test=y_test, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=plot_)\n",
    "        clear_output(wait=True)\n",
    "        dnn.save_weights(f'figure{digit_figure}/dnns/pretrain_dnn_{name}.pkl')\n",
    "        save_list(losses_pretrain, f'figure{digit_figure}/losses/pretrain_losses_{name}.pkl')\n",
    "        save_list(accuracies_pretrain, f'figure{digit_figure}/losses/pretrain_accuracies_{name}.pkl')\n",
    "        save_list(val_losses_pretrain, f'figure{digit_figure}/losses/pretrain_val_losses_{name}.pkl')\n",
    "        save_list(val_accuracies_pretrain, f'figure{digit_figure}/losses/pretrain_val_accuracies_{name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [2, 3, 5, 7, 10]\n",
    "create_dirs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_layer in nb_layers:\n",
    "    print(f'Nb layer: {nb_layer}')\n",
    "    neurons = [200]*nb_layer\n",
    "    run_and_save(1, nb_layer, nb_layer, neurons, suptitle=f'{nb_layers} layers',\n",
    "                 X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_nb_layers, accuracies_nb_layers, val_losses_nb_layers, val_accuracies_nb_layers = [], [], [], []\n",
    "for nb_layer in layers:\n",
    "    losses = open_list(f'figure1/losses/losses_{nb_layer}.pkl')\n",
    "    accuracies = open_list(f'figure1/losses/accuracies_{nb_layer}.pkl')\n",
    "    val_losses = open_list(f'figure1/losses/val_losses_{nb_layer}.pkl')\n",
    "    val_accuracies = open_list(f'figure1/losses/val_accuracies_{nb_layer}.pkl')\n",
    "    \n",
    "    losses_pretrain = open_list(f'figure1/losses/pretrain_losses_{nb_layer}.pkl')\n",
    "    accuracies_pretrain = open_list(f'figure1/losses/pretrain_accuracies_{nb_layer}.pkl')\n",
    "    val_losses_pretrain = open_list(f'figure1/losses/pretrain_val_losses_{nb_layer}.pkl')\n",
    "    val_accuracies_pretrain = open_list(f'figure1/losses/pretrain_val_accuracies_{nb_layer}.pkl')\n",
    "    \n",
    "    losses_nb_layers.append((losses, losses_pretrain))\n",
    "    accuracies_nb_layers.append((accuracies, accuracies_pretrain))\n",
    "    val_losses_nb_layers.append((val_losses, val_losses_pretrain))\n",
    "    val_accuracies_nb_layers.append((val_accuracies, val_accuracies_pretrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(layers), 2, figsize=(10, 4*len(layers)))\n",
    "for i in range(len(layers)):\n",
    "    plot(i, losses_nb_layers, accuracies_nb_layers, val_losses_nb_layers, val_accuracies_nb_layers, ax=axs[i], \n",
    "         xlabel=f'{layers[i]} layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_neurons = [100, 200, 700, 1000]\n",
    "create_dirs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_neuron in nb_neurons:\n",
    "    neurons = [nb_neuron]*2\n",
    "    print(f'Nb neurons: {nb_neuron}')\n",
    "    run_and_save(2, nb_neuron, 2, neurons, suptitle=f'{nb_neuron} neurons',\n",
    "                 X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_nb_neurons, accuracies_nb_neurons, val_losses_nb_neurons, val_accuracies_nb_neurons = [], [], [], []\n",
    "for nb_neuron in nb_neurons:\n",
    "    losses = open_list(f'figure2/losses/losses_{nb_neuron}.pkl')\n",
    "    accuracies = open_list(f'figure2/losses/accuracies_{nb_neuron}.pkl')\n",
    "    val_losses = open_list(f'figure2/losses/val_losses_{nb_neuron}.pkl')\n",
    "    val_accuracies = open_list(f'figure2/losses/val_accuracies_{nb_neuron}.pkl')\n",
    "    \n",
    "    losses_pretrain = open_list(f'figure2/losses/pretrain_losses_{nb_neuron}.pkl')\n",
    "    accuracies_pretrain = open_list(f'figure2/losses/pretrain_accuracies_{nb_neuron}.pkl')\n",
    "    val_losses_pretrain = open_list(f'figure2/losses/pretrain_val_losses_{nb_neuron}.pkl')\n",
    "    val_accuracies_pretrain = open_list(f'figure2/losses/pretrain_val_accuracies_{nb_neuron}.pkl')\n",
    "    \n",
    "    losses_nb_neurons.append((losses, losses_pretrain))\n",
    "    accuracies_nb_neurons.append((accuracies, accuracies_pretrain))\n",
    "    val_losses_nb_neurons.append((val_losses, val_losses_pretrain))\n",
    "    val_accuracies_nb_neurons.append((val_accuracies, val_accuracies_pretrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(nb_neurons), 2, figsize=(10, 4*len(nb_neurons)))\n",
    "for i in range(len(nb_neurons)):\n",
    "    plot(i, losses_nb_neurons, accuracies_nb_neurons, val_losses_nb_neurons, val_accuracies_nb_neurons, ax=axs[i], \n",
    "         xlabel=f'{nb_neurons[i]} neurons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenTrains = [1000, 3000, 7000, 10_000, 30_000, 60_000]\n",
    "create_dirs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lenTrain in lenTrains:\n",
    "    print(f'Length train: {lenTrain}')\n",
    "    indices = np.random.choice(range(len(X_train)), size=lenTrain, replace=False)\n",
    "    sub_X_train = X_train[indices]\n",
    "    sub_y_train = y_train[indices]\n",
    "    \n",
    "    run_and_save(3, lenTrain, 2, [200, 200], suptitle=f'{lenTrain} training samples',\n",
    "                 X_train=sub_X_train, y_train=sub_y_train, X_test=X_test, y_test=y_test, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, plot_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_nb_train, accuracies_nb_train, val_losses_nb_train, val_accuracies_nb_train = [], [], [], []\n",
    "for lenTrain in lenTrains:\n",
    "    losses = open_list(f'figure3/losses/losses_{lenTrain}.pkl')\n",
    "    accuracies = open_list(f'figure3/losses/accuracies_{lenTrain}.pkl')\n",
    "    val_losses = open_list(f'figure3/losses/val_losses_{lenTrain}.pkl')\n",
    "    val_accuracies = open_list(f'figure3/losses/val_accuracies_{lenTrain}.pkl')\n",
    "    \n",
    "    losses_pretrain = open_list(f'figure3/losses/pretrain_losses_{lenTrain}.pkl')\n",
    "    accuracies_pretrain = open_list(f'figure3/losses/pretrain_accuracies_{lenTrain}.pkl')\n",
    "    val_losses_pretrain = open_list(f'figure3/losses/pretrain_val_losses_{lenTrain}.pkl')\n",
    "    val_accuracies_pretrain = open_list(f'figure3/losses/pretrain_val_accuracies_{lenTrain}.pkl')\n",
    "    \n",
    "    losses_nb_train.append((losses, losses_pretrain))\n",
    "    accuracies_nb_train.append((accuracies, accuracies_pretrain))\n",
    "    val_losses_nb_train.append((val_losses, val_losses_pretrain))\n",
    "    val_accuracies_nb_train.append((val_accuracies, val_accuracies_pretrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(lenTrains), 2, figsize=(10, 4*len(lenTrains)))\n",
    "for i in range(len(lenTrains)):\n",
    "    plot(i, losses_nb_train, accuracies_nb_train, val_losses_nb_train, val_accuracies_nb_train, ax=axs[i], \n",
    "         xlabel=f'{lenTrains[i]} training samples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
